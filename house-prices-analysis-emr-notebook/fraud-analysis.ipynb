{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## House Prices Fraud Detection\n",
    "\n",
    "The purpose of this notebook is to demostrate an example scenario for House Prices Fraud Analysis. Various Tax authorities around the world are facing fraud when it comes to house prices. Sometimes the price paid is under reported, something that in most countries is illegal and leads to reduced tax reciepts.\n",
    "\n",
    "The fraud detection problem can be translated into an anomaly detection problem. If price is very low considering the location and of course the type and the location of the property. Property size, number or bedrooms etc, all might play a singificant role. \n",
    "\n",
    "For this notebook we consider the following dataset <a href=\"https://www.kaggle.com/hm-land-registry/uk-housing-prices-paid\">dataset</a> found in kaggle.com. The dataset is simply the price paid. In previous demo I have used the AWS Glue Databrew to split dataset into training and test dataset. First, let's load the file into a Spark Dataframe.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bd933da464c46c388d90cb689c7bb7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>0</td><td>application_1608586772828_0001</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-11-47.eu-west-1.compute.internal:20888/proxy/application_1608586772828_0001/\" >Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-6-241.eu-west-1.compute.internal:8042/node/containerlogs/container_1608586772828_0001_01_000001/livy\" >Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- price_paid: string (nullable = true)\n",
      " |-- date_of_transfer: string (nullable = true)\n",
      " |-- property_type: string (nullable = true)\n",
      " |-- new: string (nullable = true)\n",
      " |-- duration: string (nullable = true)\n",
      " |-- town: string (nullable = true)\n",
      " |-- district: string (nullable = true)\n",
      " |-- county: string (nullable = true)\n",
      " |-- category_type: string (nullable = true)\n",
      " |-- record_status: string (nullable = true)"
     ]
    }
   ],
   "source": [
    "dataset_location = \"s3://samatas/house_prices_fraud/edited/rename_16Dec2020_1608136675571/rename_16Dec2020_1608136675571_part00000.csv\"\n",
    "dataset = spark.read.format(\"csv\").option(\"header\", \"true\").load(dataset_location)\n",
    "dataset = dataset.cache()\n",
    "dataset.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's just count the two different datasets, just to validate that the split was succesful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7947b640b1924e919e2371485cb8e88c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the dataset is 22,489,348"
     ]
    }
   ],
   "source": [
    "import locale\n",
    "locale.setlocale(locale.LC_ALL, 'en_US')\n",
    "print(\"Size of the dataset is \" + locale.format(\"%d\",dataset.count(),grouping=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd4b636e490a4f08a40d8ec048897006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+----------------+-------------+---+--------+----------+------------------+------------------+-------------+-------------+\n",
      "|                  id|price_paid|date_of_transfer|property_type|new|duration|      town|          district|            county|category_type|record_status|\n",
      "+--------------------+----------+----------------+-------------+---+--------+----------+------------------+------------------+-------------+-------------+\n",
      "|{81B82214-7FBC-41...|     25000|1995-08-18 00:00|            T|  N|       F|    OLDHAM|            OLDHAM|GREATER MANCHESTER|            A|            A|\n",
      "|{8046EC72-1466-42...|     42500|1995-08-09 00:00|            S|  N|       F|     GRAYS|          THURROCK|          THURROCK|            A|            A|\n",
      "|{278D581A-5BF3-4F...|     45000|1995-06-30 00:00|            T|  N|       F|HIGHBRIDGE|         SEDGEMOOR|          SOMERSET|            A|            A|\n",
      "|{1D861C06-A416-48...|     43150|1995-11-24 00:00|            T|  N|       F|   BEDFORD|NORTH BEDFORDSHIRE|      BEDFORDSHIRE|            A|            A|\n",
      "|{DD8645FD-A815-43...|     18899|1995-06-23 00:00|            S|  N|       F| WAKEFIELD|             LEEDS|    WEST YORKSHIRE|            A|            A|\n",
      "+--------------------+----------+----------------+-------------+---+--------+----------+------------------+------------------+-------------+-------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "dataset.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For Linear Regression we need numerical values. For that reason we can use the Spark ML built in library for String Indexing. For this example let's start with the property type. First let's explore what are the different property types in our dataset. For this purpose I will use the train dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "191e87649d244f3c9bdef40152f7baa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+\n",
      "|property_type|  count|\n",
      "+-------------+-------+\n",
      "|            D|5170327|\n",
      "|            S|6216218|\n",
      "|            T|6918811|\n",
      "|            F|4083424|\n",
      "|            O| 100568|\n",
      "+-------------+-------+"
     ]
    }
   ],
   "source": [
    "dataset.groupby(\"property_type\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that we only have 5 different types of property. Let's now index them and see the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ac454d6ff64bacb12a75f836cfa9c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+----------------+-------------+---+--------+----------+------------------+------------------+-------------+-------------+-------------------+\n",
      "|                  id|price_paid|date_of_transfer|property_type|new|duration|      town|          district|            county|category_type|record_status|property_type_index|\n",
      "+--------------------+----------+----------------+-------------+---+--------+----------+------------------+------------------+-------------+-------------+-------------------+\n",
      "|{81B82214-7FBC-41...|     25000|1995-08-18 00:00|            T|  N|       F|    OLDHAM|            OLDHAM|GREATER MANCHESTER|            A|            A|                0.0|\n",
      "|{8046EC72-1466-42...|     42500|1995-08-09 00:00|            S|  N|       F|     GRAYS|          THURROCK|          THURROCK|            A|            A|                1.0|\n",
      "|{278D581A-5BF3-4F...|     45000|1995-06-30 00:00|            T|  N|       F|HIGHBRIDGE|         SEDGEMOOR|          SOMERSET|            A|            A|                0.0|\n",
      "|{1D861C06-A416-48...|     43150|1995-11-24 00:00|            T|  N|       F|   BEDFORD|NORTH BEDFORDSHIRE|      BEDFORDSHIRE|            A|            A|                0.0|\n",
      "|{DD8645FD-A815-43...|     18899|1995-06-23 00:00|            S|  N|       F| WAKEFIELD|             LEEDS|    WEST YORKSHIRE|            A|            A|                1.0|\n",
      "+--------------------+----------+----------------+-------------+---+--------+----------+------------------+------------------+-------------+-------------+-------------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"property_type\", outputCol=\"property_type_index\")\n",
    "prepared_dataset = indexer.fit(dataset).transform(dataset)\n",
    "prepared_dataset.show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7458426ba78442229953e06a21cc249d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- price_paid: string (nullable = true)\n",
      " |-- date_of_transfer: string (nullable = true)\n",
      " |-- property_type: string (nullable = true)\n",
      " |-- new: string (nullable = true)\n",
      " |-- duration: string (nullable = true)\n",
      " |-- town: string (nullable = true)\n",
      " |-- district: string (nullable = true)\n",
      " |-- county: string (nullable = true)\n",
      " |-- category_type: string (nullable = true)\n",
      " |-- record_status: string (nullable = true)\n",
      " |-- property_type_index: double (nullable = false)"
     ]
    }
   ],
   "source": [
    "prepared_dataset.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice, the `property_type_index` is of type `double`, which is exactly what we wanted. At this stage though, we notice that the `price_paid` column  is of type `string`. Let's try convert it to a numerical data type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c835e1acd2f04f3c994ec498549a6547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+----------------+-------------+---+--------+----------+------------------+------------------+-------------+-------------+-------------------+\n",
      "|                  id|price_paid|date_of_transfer|property_type|new|duration|      town|          district|            county|category_type|record_status|property_type_index|\n",
      "+--------------------+----------+----------------+-------------+---+--------+----------+------------------+------------------+-------------+-------------+-------------------+\n",
      "|{81B82214-7FBC-41...|     25000|1995-08-18 00:00|            T|  N|       F|    OLDHAM|            OLDHAM|GREATER MANCHESTER|            A|            A|                0.0|\n",
      "|{8046EC72-1466-42...|     42500|1995-08-09 00:00|            S|  N|       F|     GRAYS|          THURROCK|          THURROCK|            A|            A|                1.0|\n",
      "|{278D581A-5BF3-4F...|     45000|1995-06-30 00:00|            T|  N|       F|HIGHBRIDGE|         SEDGEMOOR|          SOMERSET|            A|            A|                0.0|\n",
      "|{1D861C06-A416-48...|     43150|1995-11-24 00:00|            T|  N|       F|   BEDFORD|NORTH BEDFORDSHIRE|      BEDFORDSHIRE|            A|            A|                0.0|\n",
      "|{DD8645FD-A815-43...|     18899|1995-06-23 00:00|            S|  N|       F| WAKEFIELD|             LEEDS|    WEST YORKSHIRE|            A|            A|                1.0|\n",
      "+--------------------+----------+----------------+-------------+---+--------+----------+------------------+------------------+-------------+-------------+-------------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "prepared_dataset = prepared_dataset.withColumn(\"price_paid\", prepared_dataset[\"price_paid\"].cast(IntegerType()))\n",
    "prepared_dataset.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's repeat the process for the `town` feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f1b968be49d48e1a98594d0d6fdfe2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indexer = StringIndexer(inputCol=\"town\", outputCol=\"town_index\")\n",
    "prepared_dataset = indexer.fit(prepared_dataset).transform(prepared_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's take the year the property was sold and add it as another column that needs to be indexed. First, we need to extract the year from the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbafff295caa4912821c684360a9120c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- price_paid: integer (nullable = true)\n",
      " |-- date_of_transfer: string (nullable = true)\n",
      " |-- property_type: string (nullable = true)\n",
      " |-- new: string (nullable = true)\n",
      " |-- duration: string (nullable = true)\n",
      " |-- town: string (nullable = true)\n",
      " |-- district: string (nullable = true)\n",
      " |-- county: string (nullable = true)\n",
      " |-- category_type: string (nullable = true)\n",
      " |-- record_status: string (nullable = true)\n",
      " |-- property_type_index: double (nullable = false)\n",
      " |-- town_index: double (nullable = false)\n",
      " |-- year_of_transfer: integer (nullable = true)"
     ]
    }
   ],
   "source": [
    "prepared_dataset = prepared_dataset.withColumn('year_of_transfer', prepared_dataset['date_of_transfer'].substr(1, 4))\n",
    "prepared_dataset = prepared_dataset.withColumn(\"year_of_transfer\", prepared_dataset[\"year_of_transfer\"].cast(IntegerType()))\n",
    "prepared_dataset.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to split the dataset into two parts, training and test. In order to do that we can use the built-in function of Apache Spark random split that allows us to randomly split our dataset giving specific weights. For this example, we will allocate 80% for model training and 20% for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89e47714b00e43b4a2cb1c9d41d230c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "splits = prepared_dataset.randomSplit([0.8, 0.2])\n",
    "train = splits[0]\n",
    "test = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1e9e3da942b4d67bfd2e179ab49f69f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset is 17,993,102\n",
      "Size of test dataset is 4,496,246"
     ]
    }
   ],
   "source": [
    "print(\"Size of train dataset is \" + locale.format(\"%d\",train.count(),grouping=True))\n",
    "print(\"Size of test dataset is \" + locale.format(\"%d\",test.count(),grouping=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d88df64ef94545dc81665232391be717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[ \"property_type_index\", \"town_index\",\"year_of_transfer\"],\n",
    "    outputCol=\"features\")\n",
    "training = assembler.transform(train)\n",
    "lr = LinearRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8).setLabelCol(\"price_paid\")\n",
    "lrModel = lr.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b89e088971b24598b38f2dbd80dcb132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [32020.562122876876,-2.245252766067222,11567.104989562413]\n",
      "Intercept: -23056521.72478374\n",
      "numIterations: 6\n",
      "objectiveHistory: [0.4999999999999999, 0.49055061404863065, 0.481015457287159, 0.47863065259146675, 0.47803444273831025, 0.4778357060209848]\n",
      "+-------------------+\n",
      "|          residuals|\n",
      "+-------------------+\n",
      "|  -16175.4566793181|\n",
      "|-11307.487819101661|\n",
      "|  52960.72514574602|\n",
      "| -35914.41576190293|\n",
      "|  75126.70848384872|\n",
      "|  846.9086215086281|\n",
      "|  156398.2706067264|\n",
      "|-20900.944245308638|\n",
      "| -4814.560096248984|\n",
      "| 13205.647178642452|\n",
      "| 19680.594550233334|\n",
      "| -35433.66074741259|\n",
      "| 1279.1122651137412|\n",
      "|  21167.47788162157|\n",
      "|-24333.231814343482|\n",
      "|   52858.5769601576|\n",
      "|  56126.70848384872|\n",
      "|  235147.2706067264|\n",
      "| -99659.06138571724|\n",
      "|-22688.236829079688|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "RMSE: 384335.690430\n",
      "r2: 0.044329"
     ]
    }
   ],
   "source": [
    "print(\"Coefficients: %s\" % str(lrModel.coefficients))\n",
    "print(\"Intercept: %s\" % str(lrModel.intercept))\n",
    "\n",
    "# Summarize the model over the training set and print out some metrics\n",
    "trainingSummary = lrModel.summary\n",
    "print(\"numIterations: %d\" % trainingSummary.totalIterations)\n",
    "print(\"objectiveHistory: %s\" % str(trainingSummary.objectiveHistory))\n",
    "trainingSummary.residuals.show()\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % trainingSummary.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81708d9549f04ba8a2e008e9446582c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------+------------------+\n",
      "|        prediction|price_paid|          features|\n",
      "+------------------+----------+------------------+\n",
      "| 19596.77057794109|     33000|[0.0,114.0,1995.0]|\n",
      "|19567.582291983068|     16000|[0.0,127.0,1995.0]|\n",
      "|115914.41576190293|     55000|  [3.0,0.0,1995.0]|\n",
      "|19408.169345591217|     39250|[0.0,198.0,1995.0]|\n",
      "|18965.854550678283|     54000|[0.0,395.0,1995.0]|\n",
      "+------------------+----------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "R Squared (R2) on test data = 0.0470255"
     ]
    }
   ],
   "source": [
    "testing = assembler.transform(test)\n",
    "lr_predictions = lrModel.transform(testing)\n",
    "\n",
    "lr_predictions.select(\"prediction\",\"price_paid\",\"features\").show(5)\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "lr_evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"price_paid\",metricName=\"r2\")\n",
    "print(\"R Squared (R2) on test data = %g\" % lr_evaluator.evaluate(lr_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write our predictions back to s3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbb0240da2c645308acf646dcde4d58d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_predictions.write.parquet(\"s3://samatas/house_prices_fraud/predictions/\",mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

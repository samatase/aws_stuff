AWSTemplateFormatVersion: '2010-09-09'
Description: Provision an EMR/Spark cluster with Hail and Jupyter Notebooks
Metadata:
  AWS::CloudFormation::Interface:
    ParameterGroups:
    - Label:
        default: EMR Options
      Parameters:
        - JupyterPassword
        - EC2KeyName
        - VPC
        - Subnet
        - CoreNodeCount
        - DiskSizeGB
        - InstanceType
        - AccessFromCIDRBlock
        - JupyterPort
        - HailBuildOutputS3Path
        - HailBuildHailVersion
        - HailBuildSparkVersion
    - Label:
        default: Tags
      Parameters:
        - NameTag
        - OwnerTag
        - PurposeTag
Parameters:
  EnvironmentName:
    Type: String
    Description: >
      An environment name that will be prefixed to resource names including
      exported values. Should be unique per region.
  JupyterPassword:
    AllowedPattern: >-
      [a-zA-Z0-9!^*_+-]*
    ConstraintDescription: >
      Can only contain alphanumeric characters or the following
      special characters !^*-_+, between 8 and 28 characters
    Description: Password Jupyter Notebook login (between 8 and 28 characters)
    MaxLength: 28
    MinLength: 8
    NoEcho: true
    Type: String
  EC2KeyName:
    Description: SSH key pair to use for EMR node login
    Type: AWS::EC2::KeyPair::KeyName
  VPC:
    Description: VPC for EMR nodes.
    Type: AWS::EC2::VPC::Id
  Subnet:
    Description: Subnet for EMR nodes, from the VPC selected above
    Type: AWS::EC2::Subnet::Id
  CoreNodeCount:
    Description: Number of core nodes to provision (1-20)
    Type: Number
    MinValue: '1'
    MaxValue: '80'
    Default: '10'
  DiskSizeGB:
    Description: EBS Volume size (GB) for each node
    Type: Number
    MinValue: '50'
    MaxValue: '1000'
    Default: '500'
  InstanceType:
    Type: String
    Default: m4.16xlarge
    AllowedValues:
      - m4.large
      - m4.xlarge
      - m4.2xlarge
      - m4.4xlarge
      - m4.10xlarge
      - m4.16xlarge
      - c4.large
      - c4.xlarge
      - c4.2xlarge
      - c4.4xlarge
      - c4.8xlarge
      - r3.xlarge
      - r3.2xlarge
      - r3.4xlarge
      - r3.8xlarge
    Description: EMR node ec2 instance type - you can add more types by expanding
      on this list.
  OwnerTag:
    Type: String
    Default: Owner
    MinLength: 1
    Description: Your name - used to tag the cluster
  PurposeTag:
    Type: String
    MinLength: 1
    Default: Genomic
    Description: Purpose - used to tag the cluster
  NameTag:
    Type: String
    MinLength: 1
    Default: hail-blog
    Description: Environment name of the cluster
  AccessFromCIDRBlock:
    Type: String
    MinLength: 9
    Default: 0.0.0.0/0
    Description: Restrict WebUI access to specified address or range - default 'anywhere'
  JupyterPort:
    Type: Number
    Default: 8192
    Description: Port for Jupyter service to listen on
  HailBuildOutputS3Path:
    Type: String
    MinLength: 1
    Default: your-output-bucket/
    Description: S3 bucket and prefix for saving the compiled Hail files
  HailBuildHailVersion:
    Type: String
    MinLength: 1
    Default: 0.1
    Description: Hail version to build
  HailBuildSparkVersion:
    Type: String
    MinLength: 1
    Default: 2.1.0
    Description: Spark version to compile Hail against
Resources:
  EMRBucket:
    Type: AWS::S3::Bucket
    DeletionPolicy: Retain
  AllowWebUIs:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Jupyter
      VpcId:
        Ref: VPC
      SecurityGroupIngress:
      - IpProtocol: tcp
        FromPort: !Ref JupyterPort
        ToPort: !Ref JupyterPort
        CidrIp:
          Ref: AccessFromCIDRBlock
  rEMREC2InstanceProfile:
    Properties:
      Path: "/"
      Roles:
      - Ref: rEMREC2Role
    Type: AWS::IAM::InstanceProfile
  rEMREC2Role:
    Type: AWS::IAM::Role
    Properties:
      Path: "/"
      AssumeRolePolicyDocument:
        Statement:
        - Action:
          - sts:AssumeRole
          Effect: Allow
          Principal:
            Service:
            - ec2.amazonaws.com
        Version: '2012-10-17'
      ManagedPolicyArns:
      - arn:aws:iam::aws:policy/service-role/AmazonElasticMapReduceforEC2Role
      Policies:
      - PolicyName: Athena-for-EMR
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Resource: "*"
            Action:
            - athena:*
            Effect: Allow
  rEMRServiceRole:
    Type: AWS::IAM::Role
    Properties:
      Path: "/"
      AssumeRolePolicyDocument:
        Statement:
        - Action:
          - sts:AssumeRole
          Effect: Allow
          Principal:
            Service:
            - elasticmapreduce.amazonaws.com
        Version: '2012-10-17'
      ManagedPolicyArns:
      - arn:aws:iam::aws:policy/service-role/AmazonElasticMapReduceRole
  SparkCluster:
    DependsOn: EMRCleanup
    Type: AWS::EMR::Cluster
    Properties:
      Applications:
      - Name: Hadoop
      - Name: Hive
      - Name: Spark
      - Name: Ganglia
      BootstrapActions:
      - Name: Install-decorator
        ScriptBootstrapAction:
          Path: file:/usr/bin/sudo
          Args:
          - "pip"
          - "install"
          - "decorator==4.2.1"
      - Name: Build-Hail
        ScriptBootstrapAction:
          Path: "s3://aws-bigdata-blog/artifacts/hail-on-emr/build_hail.sh"
          Args:
          - "--output-path"
          - !Sub "s3://${HailBuildOutputS3Path}"
          - "--hail-version"
          - Ref: HailBuildHailVersion
          - "--spark-version"
          - Ref: HailBuildSparkVersion
      - Name: Install-Python-Jupyter
        ScriptBootstrapAction:
          Path: s3://aws-bigdata-blog/artifacts/aws-blog-emr-jupyter/install-jupyter-emr5.sh
          Args:
          - "--toree"
          - "--ds-packages"
          - "--ml-packages"
          - "--python-packages"
          - "ggplot"
          - "--password"
          - Ref: JupyterPassword
          - "--port"
          - Ref: JupyterPort
          - "--ssl"
          - "--cached-install"
          - "--spark-opts"
          - "--jars /home/hadoop/hail-all-spark.jar"
      Configurations:
      - Classification: spark-defaults
        ConfigurationProperties:
          spark.driver.extraClassPath: "/usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:./hail-all-spark.jar"
          spark.executor.extraClassPath: "/usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:./hail-all-spark.jar"
          spark.hadoop.io.compression.codecs: "org.apache.hadoop.io.compress.DefaultCodec,is.hail.io.compress.BGzipCodec,org.apache.hadoop.io.compress.GzipCodec"
          spark.serializer: "org.apache.spark.serializer.KryoSerializer"
          spark.hadoop.parquet.block.size: "1099511627776"
          spark.sql.files.maxPartitionBytes: "1099511627776"
          spark.sql.files.openCostInBytes: "1099511627776"
        Configurations: []
      Instances:
        AdditionalMasterSecurityGroups:
        - Fn::GetAtt:
          - AllowWebUIs
          - GroupId
        Ec2KeyName:
          Ref: EC2KeyName
        Ec2SubnetId:
          Ref: Subnet
        MasterInstanceGroup:
          InstanceCount: 1
          InstanceType:
            Ref: InstanceType
        CoreInstanceGroup:
          InstanceCount:
            Ref: CoreNodeCount
          InstanceType:
            Ref: InstanceType
          EbsConfiguration:
            EbsOptimized: true
            EbsBlockDeviceConfigs:
            - VolumeSpecification:
                SizeInGB:
                  Ref: DiskSizeGB
                VolumeType: standard
      Name: spark-hail
      JobFlowRole:
        Ref: rEMREC2InstanceProfile
      ServiceRole:
        Ref: rEMRServiceRole
      ReleaseLabel: emr-5.5.0
      LogUri: !Sub "s3://${EMRBucket}"
      Tags:
      - Key: Name
        Value: !Sub "${NameTag}-hail-spark"
      - Key: Owner
        Value:
          Ref: OwnerTag
      - Key: Purpose
        Value:
          Ref: PurposeTag
  EMRCleanup:
    Type: Custom::EMRCleanup
    Properties:
      ServiceToken: !GetAtt EMRCleanupFunction.Arn
  EMRCleanupFunction:
    Type: AWS::Lambda::Function
    Properties:
      Handler: index.handler
      Role: !GetAtt EMRCleanupExecutionRole.Arn
      Runtime: python2.7
      Timeout: 300
      Code:
        ZipFile: !Sub |
            from __future__ import print_function
            import json
            import boto3
            import cfnresponse
            import time
            def handler(event, context):
                print(json.dumps(event))
                if (event["RequestType"] == "Delete"):
                    try:
                        deleteSecurityGroups("${VPC}")
                    except Exception as e:
                        print("Exception thrown: %s" % str(e))
                        pass
                else:
                    print("RequestType %s, nothing to do" % event["RequestType"])
                time.sleep(30)  # pause for CloudWatch logs
                print('Done')
                responseData={"Data":"OK"}
                cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData)
            def deleteSecurityGroups(vpcid):
                time.sleep(30)  # delay to avoid dependency race condition
                ec2 = boto3.resource('ec2')
                vpc = ec2.Vpc(vpcid)
                # Fist, delete EMR Default VPC Security Group Rules
                for sg in vpc.security_groups.all():
                   if "ElasticMapReduce" not in sg.group_name:
                       continue
                   print("Deleting rules for SG: " + str(sg))
                   for rule in sg.ip_permissions:
                       try:
                           sg.revoke_ingress(
                               IpPermissions=[{
                                   "IpProtocol":rule["IpProtocol"],
                                   "FromPort":rule["FromPort"],
                                   "ToPort":rule["ToPort"],
                                   "UserIdGroupPairs":rule["UserIdGroupPairs"]}]
                               )
                       except Exception as e:
                           print(str(e))
                # Now, delete the VPC Security Groups
                for sg in vpc.security_groups.all():
                   if "ElasticMapReduce" not in sg.group_name:
                       continue
                   print("Deleting SG: " + str(sg))
                   try:
                       sg.delete()
                   except Exception as e:
                       print(str(e))
                       pass
  EMRCleanupExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            Service:
            - lambda.amazonaws.com
          Action:
          - sts:AssumeRole
      Path: "/"
      Policies:
      - PolicyName: LogsForLambda
        PolicyDocument:
          Version: 2012-10-17
          Statement:
            - Effect: Allow
              Action:
                - logs:CreateLogGroup
                - logs:CreateLogStream
                - logs:PutLogEvents
              Resource:
                - !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:log-group:/aws/lambda/*"
                - !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:log-group:/aws/lambda/*:*"
      - PolicyName: EC2DescribeDeleleRevokeSg
        PolicyDocument:
          Version: 2012-10-17
          Statement:
            - Effect: Allow
              Action:
                - ec2:Describe*
                - ec2:DeleteSecurityGroup
                - ec2:RevokeSecurityGroupIngress
              Resource: '*'
              Condition:
                ArnEqualsIfExists:
                  ec2:Vpc: !Sub "arn:aws:ec2:${AWS::Region}:${AWS::AccountId}:vpc/${VPC}"

Outputs:
  JupyterURL:
    Description: Open Jupyter on your new PySpark/EMR cluster
    Value: !Sub "https://${SparkCluster.MasterPublicDNS}:${JupyterPort}"
  EMRBucket:
    Description: EMR Scratch data and Logs bucket
    Value: !Ref EMRBucket
